# Yelp(enumerated questions)

## Description

This repository is the source code of the paper *Adapting User Preference to Online Feedback in Multi-round Conversational Recommendation* implemented via PyTorch.

## Requirement
- `torch==1.4.0`   
- `torch_geometric==1.4.3`
- `tqdm`
- `sklearn`

## Dataset
The dataset download link: `https://drive.google.com/file/d/1qUsdTGHPqawgJ04wx0YtfF8GCRRQYDav/view?usp=sharing`
Put the files in Data/Yelp_data/ to /data/ folder.

## Usage
* **To train FPAN model:**
  ``python offline_train_rec.py``
  The model paramters will be saved in `\recommendersystem\recmodel`
* **To train policy network in conversational component:**
  The  policy network is first trained with supervised learning to imitate the policy generated by a rule-based agent. Then it is trained with Policy Gradient through interaction with user simulator
  - `python make_agent_pretrain_data.py`: create data for supervised learning.(optional) 
    Since different recommendation model generates different state representation, the data for supervised learning need to be generated based on current recommendation model. 
	We provided dataset generated based on our FPAN model.
  - `python train_agent_ear.py --mode pretrain`: train policy network with supervised learning.
    The model parameters will be saved in `\agents\agent_ear`
  - `python train_agent_ear.py --mode PG`: further train policy network with Policy Gradient.
    The model parameters will be saved in `\agents\agent_ear`
* **To directly evaluate FPAN and EAR(FPAN):**
  We provided the model parameters in corresponding folder.
  - `python offline_test_rec.py`: evaluate FPAN model
  - `python test_agent_ear.py`: evaluate EAR(FPAN) with user simulator
